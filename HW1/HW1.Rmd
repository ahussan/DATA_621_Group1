---
title: "DATA 621 Homework 1"
subtitle: "Critical Thinking Group 1"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: 
    toc: true
    toc_float: true
  pdf_document: default
  html_notebook: default
---

## Overview

In this homework assignment, we will explore, analyze and model a data set containing approximately 2200 records. Each record represents a professional baseball team from the years 1871 to 2006 inclusive. Each record has the performance of the team for the given year, with all of the statistics adjusted to match the performance of a 162 game season.

## Objective 

The objective is to build a multiple linear regression model on the training data to predict the number of wins for the team. we can only use the variables given to us (or variables that we derive from the variables provided). 

## 1. Data Exploration


### Data Summery 

```{r, echo=FALSE}
#Import required libraries
library(tidyr)
library(zoo)
library(pastecs)
library(dplyr)
library(ggplot2)
library(corrr)
library(GGally)
library(corrplot)
library(ggcorrplot)
library(reshape2)
```


```{r}
#Import the data
Data <- read.csv("moneyball-training-data.csv")
head(Data)
```

We can see that the data contain 17 columns and 2276 observations or records. The first column is the index which will be deleted as it is not useful. The target variable is the "TARGET_WINS". Notice that the dateset is numerical and does not have any categorical variables.

```{r}
#Remove the index
Data1 <- Data [-c(1)]
#Data1$INDEX = NULL
```


```{r}
#Check the Summary
summary(Data1)
```
Summary of the data gives a useful information about each variable. 

- There is a significant number of NA  values. 

- The average wins for a team is about 81.


````{r}
#The mean for each column in the data
colMeans(Data1)
```

```{r}
#The Standard Deviation for each column in the data
sapply(Data1, sd)
```

```{r}
#The median for each column in the data
apply(Data1,2, median)
```

### Missing Vlaues

```{r}
#Search if there are any NA values

sum(is.na(Data1))
```

```{r}
#We are not able to delete the NA values. We will replace NA values.

Data2 = replace(Data1, TRUE, lapply(Data1, na.aggregate))
```

```{r}
#Confirm the all NA values were replaced by the mean.
sum(is.na(Data2))
```

### Distribution


```{r}
Data2 %>%
  gather(var, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(value)) + 
  geom_density(color = "blue") + 
  facet_wrap(~var, scales= "free", ncol = 5)
         
```

The distribution of the target variable "target_wins" column is normally distributed and there are many average teams.

The distribution also show that BASERUN_SB and BATTING 3B are right skew variables. In addition, BATTING_HR and PITCHING_HR are bimodal.



### Boxplot

```{r}
Data2 %>%
  gather(var, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(value)) + 
  geom_boxplot(notch = TRUE) + 
  facet_wrap(~var, scales= "free", ncol = 4)
```
The box-plots above give us idea about the spread of each variable in the data. The box-plots reveal significant outliers.


### Correlation

```{r}
# Use pearson correlation
<<<<<<< Updated upstream
corrr:: correlate (Data2, method = "pearson")
=======
#corrr:: correlate (Data2, method = "pearson")
Data2 %>% correlate() %>% focus(TARGET_WINS)

>>>>>>> Stashed changes
```

These correlations do not show a strong relationship. This indicate presence of ‘noise’ in these relationships.

It is interesting to note allowing hits have little positive impacts on wins. 

It is also noteworthy that pitching strikeouts by batters and hits aalowed are negatively correlated with winning. I assume the correlations are affected by the outliers.

```{r}
ggcorr(Data2)
```



```{r}
#Add correlation coefficients
corr <- round(cor(Data2), 1)
ggcorrplot(corr, hc.order = TRUE, type = "lower",
   lab = TRUE)
```



# Data Preperation
```{r importing data set}
moneyball_training_data = read.csv("moneyball-training-data.csv")
```


```{r finding all NA}
na_count = sapply(moneyball_training_data, function(y) sum(is.na(y)))
na_count = data.frame(na_count)
na_count %>%
  arrange(desc(na_count)) %>%
  mutate(total_rows = nrow(moneyball_training_data)) %>%
  mutate(percent_missing = na_count / total_rows)
```
We can see that **TEAM_BATTING_HBP** is missing 91% of its data and **TEAM_BASERUN_CS** is missing around 34% of its data. This is a lot of data missing which is why those columns will be removing these. Based on online reading there is no definite cut of for how much data one should be missing before removing a column, but it is always better to have more data. With the other columns that are missing 10% of its data maybe we can fill those in with the mean and median, or entirely remove the row as there should be enough data left to train the model.

```{r removing column}
moneyball_subset = subset(moneyball_training_data, select=-c(TEAM_BATTING_HBP, TEAM_BASERUN_CS, INDEX))
```


## Replacing NA with Median
We will need to look at the distribution of the columns with missing data in order to decide if we will be using the median or mean to fill in the missing data

```{r}
missing_data = subset(moneyball_subset, select = c(TEAM_FIELDING_DP, TEAM_BASERUN_SB, TEAM_BATTING_SO, TEAM_PITCHING_SO))
missing_data = melt(missing_data)

ggplot(missing_data, aes(x = value)) + geom_histogram(binwidth = 10) + facet_wrap(~variable, scale='free')
```
We can see that not all the distribution are uniform with being bimodal or having a tail. For this reason we will be using the median to replace all the NA values as the median is less succepital to outliers.

```{r}
replace_na_with_median = function(x){
  x[is.na(x)] = median(x, na.rm=TRUE)
  return(x)
}

moneyball_fill = apply(moneyball_subset, 2, replace_na_with_median)
moneyball_fill = as.data.frame(moneyball_fill)
```



## Transformation
Checking all of the columns to see if they need any type of transformation on the column in order to create a linear line

```{r}
par(mfrow=c(2,2))


for (i in 2:ncol(moneyball_fill)){
  
  y = moneyball_subset[,1]
  x = moneyball_subset[,i]
  plot(
    x, 
    y,   
    ylab = 'TARGET_WINS',
    xlab = names(moneyball_fill)[i]
  )
}
```
We can see that none of the columns are real good candidates for a log transformation. The reason is because a log transformation on the columns will not create a more linear line with any of these columns 


## Putting Teams Into Buckets

We will be putting the dataset into buckets based on the teams winning score as this will allow us to see if there is any patterns between weak and strong teams.

```{r}
moneyball_fill$TEAM_TYPE = cut(moneyball_subset[,'TARGET_WINS'], breaks=c(0, 73, 146), include.lowest = TRUE, labels = c('Weak', 'Strong'))
```


## Creating Total Hits
Creating a column which includes the total amount of hits a team has

```{r}
moneyball_fill$TEAM_BATTING_TOTAL = (moneyball_fill$TEAM_BATTING_H + (2 * moneyball_fill$TEAM_BATTING_2B) + (3 * moneyball_fill$TEAM_BATTING_3B) + (4 * moneyball_fill$TEAM_BATTING_HR))
```

```{r}
ggplot(moneyball_fill, aes(x=TEAM_BATTING_TOTAL, y=TARGET_WINS)) + geom_smooth(method='lm') + geom_point(aes(color=TEAM_TYPE))
```

## Hit Percentage
We would like to create a column which states what is the teams hit/base they get per game. This will be calculated by summing the total amount of hits a team gets and dividing 162 game season.

```{r}
moneyball_fill$TEAM_BATTING_PERCENT =  moneyball_fill$TEAM_BATTING_TOTAL / 162
```

```{r}
ggplot(moneyball_fill, aes(x=TEAM_BATTING_PERCENT, y=TARGET_WINS)) + geom_smooth(method='lm') + geom_point(aes(color=TEAM_TYPE))
```

